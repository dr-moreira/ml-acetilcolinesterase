{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a7f90ea-f00a-42ff-88b7-085ebc4e5f76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b79bc76a-427c-4f76-b228-b849a3a1e7bd",
   "metadata": {
    "id": "H06EKcnhxLcM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import keras.layers as layers\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import glob\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import Image as IpyImage\n",
    "import imageio\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "980c3c95-6807-4f9f-b1cb-7867cf54a84c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    print(\"Invalid device or cannot modify virtual devices once initialized.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a938092-b6e1-4286-9e47-b163ebfd8fae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=2\n",
    "LATENT_DIM=256\n",
    "IMG_SIZE=256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182a2513-7584-47a6-a104-d7e56c00856b",
   "metadata": {
    "id": "QWTkli2k6GGd"
   },
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb4f0aea-2ffd-4bab-a48d-63f734546073",
   "metadata": {
    "id": "91DeiLbpxv5_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_results(images, n_cols=None):\n",
    "    '''visualizes fake images'''\n",
    "    clear_output(wait=False)  \n",
    "\n",
    "    n_cols = n_cols or len(images)\n",
    "    n_rows = (len(images) - 1) // n_cols + 1\n",
    "\n",
    "    if images.shape[-1] == 1:\n",
    "        images = np.squeeze(images, axis=-1)\n",
    "\n",
    "    plt.figure(figsize=(n_cols, n_rows))\n",
    "    \n",
    "    for index, image in enumerate(images):\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(image)\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c1b550-62a2-4649-aa0b-3d0bec159a6f",
   "metadata": {
    "id": "JXjx6s2z6IiY"
   },
   "source": [
    "## Download and Prepare the Dataset\n",
    "\n",
    "You will use the [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) dataset for this exercise. As before, you will only need to create batches of the training images. The preprocessing steps are also shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af457c4a-909f-4402-9885-4c054f7c2bf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dataset_images_paths(image_dir):\n",
    "    '''Retorna lista de caminhos para arquivos em image_dir'''\n",
    "\n",
    "    image_paths = glob.glob(os.path.join(image_dir, '*.jpg'))\n",
    "    \n",
    "    return image_paths\n",
    "\n",
    "# fnames = get_dataset_images_paths('./data/train/positivo')\n",
    "\n",
    "def map_image(img_fname):\n",
    "    '''preprocessa imagens em img_fname'''\n",
    "    \n",
    "    img_raw = tf.io.read_file(img_fname)\n",
    "    image = tf.image.decode_jpeg(img_raw)\n",
    "    #image = tf.image.rgb_to_grayscale(image)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    #image = RGB2HSD(image)\n",
    "    image = tf.reshape(image, shape=(IMG_SIZE, IMG_SIZE, 3,))\n",
    "    \n",
    "    return image\n",
    "\n",
    "def map_hsd(img_fname):\n",
    "    image = cv2.cvtColor(cv2.imread(img_fname), cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.normalize(image, None, 0, 1.0, cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_NEAREST)\n",
    "    image = RGB2HSD(image)\n",
    "    \n",
    "    return tf.cast(image, tf.float32)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3362500-3922-4183-8df7-5565d3435796",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def RGB2HSD(X):\n",
    "    eps = np.finfo(float).eps\n",
    "    X[np.where(X==0.0)] = eps\n",
    "    \n",
    "    OD = -np.log(X / 1.0)\n",
    "    D  = np.mean(OD,2)\n",
    "    D[np.where(D==0.0)] = eps\n",
    "    \n",
    "    cx = OD[:,:,0] / (D) - 1.0\n",
    "    cy = (OD[:,:,1]-OD[:,:,2]) / (np.sqrt(3.0)*D)\n",
    "    \n",
    "    D = np.expand_dims(D,2)\n",
    "    cx = np.expand_dims(cx,2)\n",
    "    cy = np.expand_dims(cy,2)\n",
    "            \n",
    "    X_HSD = np.concatenate((D,cx,cy),2)\n",
    "    return X_HSD\n",
    "    \n",
    "def HSD2RGB(X_HSD):\n",
    "    \n",
    "    X_HSD_0, X_HSD_1, X_HSD_2  = tf.split(X_HSD, [1,1,1], axis=3)\n",
    "    D_R = (X_HSD_1+1) * X_HSD_0\n",
    "    D_G = 0.5*X_HSD_0*(2-X_HSD_1 + tf.sqrt(tf.constant(3.0))*X_HSD_2)\n",
    "    D_B = 0.5*X_HSD_0*(2-X_HSD_1 - tf.sqrt(tf.constant(3.0))*X_HSD_2)\n",
    "    \n",
    "    X_OD = tf.concat([D_R,D_G,D_B],3)\n",
    "    X_RGB = 1.0 * tf.exp(-X_OD)\n",
    "    return X_RGB   \n",
    "    \n",
    "def HSD2RGB_Numpy(X_HSD):\n",
    "    \n",
    "    X_HSD_0 = X_HSD[...,0]\n",
    "    X_HSD_1 = X_HSD[...,1]\n",
    "    X_HSD_2 = X_HSD[...,2]\n",
    "    D_R = np.expand_dims(np.multiply(X_HSD_1+1 , X_HSD_0), 2)\n",
    "    D_G = np.expand_dims(np.multiply(0.5*X_HSD_0, 2-X_HSD_1 + np.sqrt(3.0)*X_HSD_2), 2)\n",
    "    D_B = np.expand_dims(np.multiply(0.5*X_HSD_0, 2-X_HSD_1 - np.sqrt(3.0)*X_HSD_2), 2)\n",
    "     \n",
    "    X_OD = np.concatenate((D_R,D_G,D_B), axis=2)\n",
    "    X_RGB = 1.0 * np.exp(-X_OD)\n",
    "    return X_RGB         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfe621ea-f95c-4e6e-bb00-5cbd4c9515dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of images in the training set: 7\n"
     ]
    }
   ],
   "source": [
    "paths = get_dataset_images_paths('./data/template')\n",
    "\n",
    "# randomiza a array de nomes de arquivo\n",
    "random.shuffle(paths)\n",
    "\n",
    "# pega o tamanho da lista de nomes de arquivos\n",
    "# pega 80% dos nomes na lista para treinamento e 20% para validação\n",
    "paths_len = len(paths)\n",
    "train_paths_len = int(paths_len * 1.0)\n",
    "\n",
    "train_paths = paths[:train_paths_len]\n",
    "\n",
    "X = []\n",
    "\n",
    "for fname in train_paths:\n",
    "    X.append(map_hsd(fname))\n",
    "\n",
    "# configura o datasete de treinamento\n",
    "training_ds = tf.data.Dataset.from_tensor_slices((X))\n",
    "# training_ds = training_ds.map(map_hsd)\n",
    "# training_ds = training_ds.batch(BATCH_SIZE)\n",
    "\n",
    "print(f'number of images in the training set: {len(X)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ed5295b-6558-49ba-a935-79334684407a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 3)\n",
      "(256, 256, 3)\n",
      "(256, 256, 3)\n",
      "(256, 256, 3)\n",
      "(256, 256, 3)\n",
      "(256, 256, 3)\n",
      "(256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "for image in training_ds:\n",
    "    print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f67c32b9-78bd-47a4-80f4-8eed8eb4f6a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#plot_results(next(training_ds.as_numpy_iterator()), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6eef139c-e51a-49ca-9540-2c21ac33fc96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tpu_grpc_url = \"grpc://\" + os.environ[\"COLAB_TPU_ADDR\"]\n",
    "# tpu_cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu_grpc_url)\n",
    "# tf.config.experimental_connect_to_cluster(tpu_cluster_resolver) \n",
    "# tf.tpu.experimental.initialize_tpu_system(tpu_cluster_resolver)   \n",
    "# strategy = tf.distribute.experimental.TPUStrategy(tpu_cluster_resolver)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9fc587b6-39fe-48b1-b107-9d4ef68597d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Utilities\n",
    "\n",
    "def _get_norm_layer(norm):\n",
    "    if norm == 'NA':\n",
    "        return lambda: lambda x: x\n",
    "    elif norm == 'batch_normalization':\n",
    "        return layers.BatchNormalization\n",
    "    elif norm == 'instance_normalization':\n",
    "        return tfa.layers.InstanceNormalization\n",
    "    elif norm == 'layer_normalization':\n",
    "        return layers.LayerNormalization\n",
    "\n",
    "\n",
    "def get_initializers():\n",
    "    return (tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02, seed=3), # conv initializer\n",
    "            tf.keras.initializers.RandomNormal(mean=1.0, stddev=0.02, seed=3)) # bn gamma initializer\n",
    "\n",
    "\n",
    "def gradient_penalty(f, real, fake, mode):\n",
    "    def _gradient_penalty(f, real, fake=None):\n",
    "        def _interpolate(a, b=None):\n",
    "            if b is None:   # interpolation in DRAGAN\n",
    "                beta = tf.random.uniform(shape=tf.shape(a), minval=0., maxval=1.)\n",
    "                b = a + 0.5 * tf.math.reduce_std(a) * beta\n",
    "            shape = [tf.shape(a)[0]] + [1] * (a.shape.ndims - 1)\n",
    "            alpha = tf.random.uniform(shape=shape, minval=0., maxval=1.)\n",
    "            inter = a + alpha * (b - a)\n",
    "            inter.set_shape(a.shape)\n",
    "            return inter\n",
    "\n",
    "        x = _interpolate(real, fake)\n",
    "        with tf.GradientTape() as t:\n",
    "            t.watch(x)\n",
    "            pred = f(x)\n",
    "        grad = t.gradient(pred, x)\n",
    "        norm = tf.norm(tf.reshape(grad, [tf.shape(grad)[0], -1]), axis=1)\n",
    "        gp = tf.reduce_mean((norm - 1.)**2)\n",
    "\n",
    "        return gp\n",
    "\n",
    "    if mode == 'none':\n",
    "        gp = tf.constant(0, dtype=real.dtype)\n",
    "    elif mode == 'dragan':\n",
    "        gp = _gradient_penalty(f, real)\n",
    "    elif mode == 'wgan-gp':\n",
    "        gp = _gradient_penalty(f, real, fake)\n",
    "\n",
    "    return gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8da9ddc3-0033-408a-a165-db2dd3b95754",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_generator(input_shape=(IMG_SIZE, IMG_SIZE, 1),\n",
    "                    output_channels=3,\n",
    "                    dim=64,\n",
    "                    n_upsamplings=4,\n",
    "                    norm='batch_normalization',\n",
    "                    name='generator'):\n",
    "  \n",
    "    Normalization = _get_norm_layer(norm)\n",
    "    conv_initializer, bn_gamma_initializer = get_initializers()\n",
    "    \n",
    "    # Definir o INPUT = espaço latente = canal D da imagem\n",
    "    x = inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    # definir o Encoder / downsampling\n",
    "    \n",
    "    x = layers.Conv2D(16, 3,  padding='same', activation='relu', kernel_initializer=conv_initializer)(x)\n",
    "    x = layers.Conv2D(32, 3,  padding='same', activation='relu', kernel_initializer=conv_initializer)(x)\n",
    "    x = layers.MaxPool2D(2, 2)(x)\n",
    "    x = layers.Conv2D(64, 3,  padding='same', activation='relu', kernel_initializer=conv_initializer)(x)\n",
    "    x = layers.MaxPool2D(2, 2)(x)\n",
    "    x = layers.Conv2D(128, 3,  padding='same', activation='relu', kernel_initializer=conv_initializer)(x)\n",
    "    x = layers.Conv2D(256, 3, padding='same', activation='relu', kernel_initializer=conv_initializer)(x)\n",
    "    \n",
    "    # decoder / upsampling\n",
    "\n",
    "    x = layers.UpSampling2D()(x)\n",
    "    x = layers.Conv2D(256, 3,  padding='same', activation='relu', kernel_initializer=conv_initializer)(x)\n",
    "    x = layers.UpSampling2D()(x)\n",
    "    x = layers.Conv2D(128, 3,  padding='same', activation='relu', kernel_initializer=conv_initializer)(x)\n",
    "    x = layers.Conv2D(32, 3,  padding='same', activation='relu', kernel_initializer=conv_initializer)(x)\n",
    "    x = layers.Conv2D(3, 3,  padding='same', activation='relu', kernel_initializer=conv_initializer)(x)\n",
    "    \n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7e8a3d12-b820-43da-98be-5190e0d15d86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 256, 256, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_39 (Conv2D)          (None, 256, 256, 16)      160       \n",
      "                                                                 \n",
      " conv2d_40 (Conv2D)          (None, 256, 256, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 128, 128, 32)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 128, 128, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 64, 64, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_42 (Conv2D)          (None, 64, 64, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_43 (Conv2D)          (None, 64, 64, 256)       295168    \n",
      "                                                                 \n",
      " up_sampling2d_6 (UpSampling  (None, 128, 128, 256)    0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_44 (Conv2D)          (None, 128, 128, 256)     590080    \n",
      "                                                                 \n",
      " up_sampling2d_7 (UpSampling  (None, 256, 256, 256)    0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_45 (Conv2D)          (None, 256, 256, 128)     295040    \n",
      "                                                                 \n",
      " conv2d_46 (Conv2D)          (None, 256, 256, 32)      36896     \n",
      "                                                                 \n",
      " conv2d_47 (Conv2D)          (None, 256, 256, 3)       867       \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 256, 256, 1)       4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,315,207\n",
      "Trainable params: 1,315,207\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "g = create_generator()\n",
    "g.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0031b4a7-64b2-4982-b801-088ef38b48a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_d_q_net(input_shape=(IMG_SIZE, IMG_SIZE, 1),\n",
    "                        dim=64,\n",
    "                        n_downsamplings=4,\n",
    "                        norm='batch_normalization',\n",
    "                        name='q_net'):\n",
    "    Normalization = _get_norm_layer(norm)\n",
    "    conv_initializer, bn_gamma_initializer = get_initializers()\n",
    "\n",
    "    x = inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    x = layers.Conv2D(32, 3,  padding='same', activation='relu', kernel_initializer=conv_initializer)(x)\n",
    "    x = layers.Conv2D(32, 3,  padding='same', activation='relu', kernel_initializer=conv_initializer)(x)\n",
    "    x = layers.MaxPool2D(2, 2)(x)\n",
    "    \n",
    "    x = layers.Conv2D(32, 3,  padding='same', activation='relu', kernel_initializer=conv_initializer)(x)\n",
    "    x = layers.MaxPool2D(2, 2)(x)\n",
    "    \n",
    "    x = layers.Conv2D(16, 3,  padding='same', activation='relu', kernel_initializer=conv_initializer)(x)\n",
    "    x = layers.MaxPool2D(2, 2)(x)\n",
    "    \n",
    "    x = layers.Conv2D(16, 3,  padding='same', activation='relu', kernel_initializer=conv_initializer)(x)\n",
    "    x = layers.MaxPool2D(2, 2)(x)\n",
    "    \n",
    "    x = layers.Conv2D(8, 3,  padding='same', activation='relu', kernel_initializer=conv_initializer)(x)\n",
    "    d_out = layers.GlobalAveragePooling2D()(x)\n",
    "    d_out = layers.Dense(1, activation='sigmoid')(d_out)\n",
    "    \n",
    "    x = layers.MaxPool2D(2, 2)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(32)(x)\n",
    "    \n",
    "    x1 = layers.Dense(8)(x)\n",
    "    x2 = layers.Dense(8)(x)\n",
    "    x3 = layers.Dense(8)(x)\n",
    "    \n",
    "    r = layers.Dense(4, activation='softmax')(x1)\n",
    "    g = layers.Dense(4, activation='softmax')(x2)\n",
    "    b = layers.Dense(4, activation='softmax')(x3)\n",
    "    \n",
    "    q_out = tf.stack([r,g,b], axis=-1)\n",
    "    \n",
    "    d_net = tf.keras.Model(inputs=inputs, outputs=d_out, name='d_net') \n",
    "    q_net = tf.keras.Model(inputs=inputs, outputs=q_out, name='q_net')\n",
    "    return (d_net, q_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f0d79a31-bacd-4faa-942b-3af2b3fa138b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.03068061 0.96931939]\n",
      " [0.2063874  0.7936126 ]\n",
      " [0.14490987 0.85509013]\n",
      " [0.21788207 0.78211793]]\n",
      "[[ 1  2  3]\n",
      " [ 4  5  6]\n",
      " [ 7  8  9]\n",
      " [10 11 12]]\n",
      "\n",
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]]\n",
      "\n",
      "[[ 70  80  90]\n",
      " [158 184 210]\n",
      " [246 288 330]]\n",
      "\n",
      "[3 0]\n"
     ]
    }
   ],
   "source": [
    "# d_model, q_model = create_d_q_net()\n",
    "# d_model.summary()\n",
    "r = np.random.dirichlet((1,9),4) \n",
    "print(r)\n",
    "noise = np.arange(1,13).reshape((3,4))\n",
    "mixture = np.arange(1,13).reshape((4,3))\n",
    "print(mixture)\n",
    "print()\n",
    "print(noise)\n",
    "print()\n",
    "C = np.dot(noise,mixture)\n",
    "print(C)\n",
    "print()\n",
    "print(np.argmax(r, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "975b97b5-6233-41e7-bd7f-0c93a3cac7ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 256, 256, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_48 (Conv2D)          (None, 256, 256, 16)      160       \n",
      "                                                                 \n",
      " conv2d_49 (Conv2D)          (None, 256, 256, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 128, 128, 32)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_50 (Conv2D)          (None, 128, 128, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 64, 64, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_51 (Conv2D)          (None, 64, 64, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_52 (Conv2D)          (None, 64, 64, 256)       295168    \n",
      "                                                                 \n",
      " up_sampling2d_8 (UpSampling  (None, 128, 128, 256)    0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_53 (Conv2D)          (None, 128, 128, 256)     590080    \n",
      "                                                                 \n",
      " up_sampling2d_9 (UpSampling  (None, 256, 256, 256)    0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_54 (Conv2D)          (None, 256, 256, 128)     295040    \n",
      "                                                                 \n",
      " conv2d_55 (Conv2D)          (None, 256, 256, 32)      36896     \n",
      "                                                                 \n",
      " conv2d_56 (Conv2D)          (None, 256, 256, 3)       867       \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 256, 256, 1)       4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,315,207\n",
      "Trainable params: 1,315,207\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"d_net\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 256, 256, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_57 (Conv2D)          (None, 256, 256, 32)      320       \n",
      "                                                                 \n",
      " conv2d_58 (Conv2D)          (None, 256, 256, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 128, 128, 32)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_59 (Conv2D)          (None, 128, 128, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 64, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_60 (Conv2D)          (None, 64, 64, 16)        4624      \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPoolin  (None, 32, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_61 (Conv2D)          (None, 32, 32, 16)        2320      \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPoolin  (None, 16, 16, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_62 (Conv2D)          (None, 16, 16, 8)         1160      \n",
      "                                                                 \n",
      " global_average_pooling2d_2   (None, 8)                0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,929\n",
      "Trainable params: 26,929\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Settings\n",
    "batch_size = 8\n",
    "resize = 128\n",
    "shape = (resize, resize, 3)\n",
    "z_dim = 512\n",
    "n_G_upsamplings = n_D_downsamplings = 5\n",
    "gradient_penalty_mode = 'none'\n",
    "out_dir = './data/tmp'\n",
    "\n",
    "if gradient_penalty_mode == 'none':\n",
    "    d_norm = 'batch_normalization'\n",
    "elif gradient_penalty_mode in ['dragan', 'wgan-gp']:\n",
    "    # Avoid using BN with GP\n",
    "    d_norm = 'layer_normalization'\n",
    "\n",
    "gradient_penalty_weight = 10.0\n",
    "\n",
    "\n",
    "# Build the GAN\n",
    "#with strategy.scope():\n",
    "# create the generator model\n",
    "model_G = create_generator(input_shape=(256, 256, 1))\n",
    "\n",
    "# create the discriminator model\n",
    "model_D, _ = create_d_q_net()\n",
    "\n",
    "# print summaries\n",
    "model_G.summary()\n",
    "model_D.summary()\n",
    "\n",
    "# set optimizers\n",
    "param_G = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "param_D = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "\n",
    "# create distributed dataset\n",
    "#dataset = strategy.experimental_distribute_dataset(dataset)\n",
    "\n",
    "# set the loss function\n",
    "loss_func = tf.keras.losses.BinaryCrossentropy(\n",
    "    from_logits=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "da0a60ed-3bac-4e23-948e-f9555485a566",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Utilities\n",
    "\n",
    "def make_grid(imgs, nrow, padding=0):\n",
    "    assert imgs.ndim == 4 and nrow > 0\n",
    "\n",
    "    batch, height, width, ch = imgs.shape\n",
    "    n = nrow * (batch // nrow + np.sign(batch % nrow))\n",
    "    ncol = n // nrow\n",
    "    pad = np.zeros((n - batch, height, width, ch), imgs.dtype)\n",
    "    x = np.concatenate([imgs, pad], axis=0)\n",
    "\n",
    "    # border padding if required\n",
    "    if padding > 0:\n",
    "        x = np.pad(x, ((0, 0), (0, padding), (0, padding), (0, 0)),\n",
    "                   \"constant\", constant_values=(0, 0))\n",
    "        height += padding\n",
    "        width += padding\n",
    "\n",
    "    x = x.reshape(ncol, nrow, height, width, ch)\n",
    "    x = x.transpose([0, 2, 1, 3, 4])  # (ncol, height, nrow, width, ch)\n",
    "    x = x.reshape(height * ncol, width * nrow, ch)\n",
    "    \n",
    "    if padding > 0:\n",
    "        x = x[:(height * ncol - padding),:(width * nrow - padding),:]\n",
    "    return x\n",
    "\n",
    "def save_img(imgs, filepath, nrow, padding=0):\n",
    "    grid_img = make_grid(imgs, nrow, padding=padding)\n",
    "    grid_img = ((grid_img + 1.0) * 127.5).astype(np.uint8)\n",
    "    with Image.fromarray(grid_img) as img:\n",
    "        img.save(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "142841c8-aa4e-40ba-91af-e7c18b531c4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_on_batch(real_img):\n",
    "#def train_on_batch(real_img1, real_img2):\n",
    "    '''trains the GAN on a given batch'''\n",
    "    # concatenate the real image inputs\n",
    "    #real_img = tf.concat([real_img1, real_img2], axis=0)\n",
    "\n",
    "    # PHASE ONE - train the discriminator\n",
    "    with tf.GradientTape() as d_tape:\n",
    "\n",
    "        # create noise input\n",
    "        z = tf.random.normal(shape=(real_img.shape[0],1, 1, z_dim))\n",
    "        real_img = real_img[...,0]\n",
    "        D = tf.reshape(real_img, [1, 256, 256, 1])\n",
    "        real_img = tf.expand_dims(real_img, axis=0)\n",
    "        \n",
    "        # generate fake images\n",
    "        fake_img = model_G(D)\n",
    "\n",
    "        # feed the fake images to the discriminator\n",
    "        fake_out = model_D(fake_img)\n",
    "\n",
    "        # feed the real images to the discriminator\n",
    "        real_out = model_D(real_img)\n",
    "\n",
    "        # use the loss function to measure how well the discriminator\n",
    "        # labels fake or real images\n",
    "        d_fake_loss = loss_func(tf.zeros_like(fake_out), fake_out)\n",
    "        d_real_loss = loss_func(tf.ones_like(real_out), real_out)\n",
    "\n",
    "        # get the total loss\n",
    "        d_loss = (d_fake_loss + d_real_loss) \n",
    "        d_loss = tf.reduce_sum(d_loss) / (batch_size * 2)\n",
    "\n",
    "        # Gradient Penalty (ignore if you set mode to `none`)\n",
    "        gp = gradient_penalty(model_D, real_img, fake_img, mode=gradient_penalty_mode)\n",
    "        gp = gp  / (batch_size * 2)\n",
    "        d_loss = d_loss + gp * gradient_penalty_weight\n",
    "\n",
    "    # get the gradients\n",
    "    gradients = d_tape.gradient(d_loss, model_D.trainable_variables)\n",
    "    \n",
    "    # update the weights of the discriminator\n",
    "    param_D.apply_gradients(zip(gradients, model_D.trainable_variables))\n",
    "    \n",
    "\n",
    "    # PHASE TWO - train the generator\n",
    "    with tf.GradientTape() as g_tape:\n",
    "        # create noise input\n",
    "        z = tf.random.normal(shape=(real_img.shape[0], 1, 1, z_dim))\n",
    "        \n",
    "        # generate fake images\n",
    "        fake_img = model_G(D)\n",
    "\n",
    "        # feed fake images to the discriminator\n",
    "        fake_out = model_D(fake_img)\n",
    "        \n",
    "        # use loss function to measure how well the generator\n",
    "        # is able to trick the discriminator (i.e. model_D should output 1's)\n",
    "        g_loss = loss_func(tf.ones_like(fake_out), fake_out)\n",
    "        g_loss = tf.reduce_sum(g_loss) / (batch_size * 2)\n",
    "    \n",
    "    # get the gradients\n",
    "    gradients = g_tape.gradient(g_loss, model_G.trainable_variables)\n",
    "\n",
    "    # update the weights of the generator\n",
    "    param_G.apply_gradients(zip(gradients, model_G.trainable_variables))\n",
    "    \n",
    "    # return the losses and fake images for monitoring\n",
    "    return d_loss, g_loss, fake_img "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ab6854b7-c8dc-4615-9bea-e125ae8daf95",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 0]: 100%|██████████| 7/7 [00:03<00:00,  1.90it/s, g_loss=0.0433, d_loss=0.0866]\n",
      "[Epoch 1]: 100%|██████████| 7/7 [00:00<00:00, 10.62it/s, g_loss=0.0433, d_loss=0.0866]\n",
      "[Epoch 2]: 100%|██████████| 7/7 [00:00<00:00, 10.45it/s, g_loss=0.0433, d_loss=0.0866]\n",
      "[Epoch 3]: 100%|██████████| 7/7 [00:00<00:00,  9.75it/s, g_loss=0.0433, d_loss=0.0866]\n",
      "[Epoch 4]: 100%|██████████| 7/7 [00:00<00:00, 10.10it/s, g_loss=0.0434, d_loss=0.0866]\n",
      "[Epoch 5]: 100%|██████████| 7/7 [00:00<00:00,  9.79it/s, g_loss=0.0435, d_loss=0.0865]\n",
      "[Epoch 6]: 100%|██████████| 7/7 [00:00<00:00,  9.66it/s, g_loss=0.0436, d_loss=0.0861]\n",
      "[Epoch 7]: 100%|██████████| 7/7 [00:00<00:00,  9.46it/s, g_loss=0.0438, d_loss=0.0852]\n",
      "[Epoch 8]: 100%|██████████| 7/7 [00:00<00:00,  9.53it/s, g_loss=0.0441, d_loss=0.0832]\n",
      "[Epoch 9]: 100%|██████████| 7/7 [00:00<00:00,  7.45it/s, g_loss=0.0448, d_loss=0.0788]\n",
      "[Epoch 10]: 100%|██████████| 7/7 [00:00<00:00,  7.36it/s, g_loss=0.0413, d_loss=0.0672]\n",
      "[Epoch 11]: 100%|██████████| 7/7 [00:00<00:00,  9.77it/s, g_loss=0.0469, d_loss=0.0619]\n",
      "[Epoch 12]: 100%|██████████| 7/7 [00:00<00:00,  9.83it/s, g_loss=0.0491, d_loss=0.0613]\n",
      "[Epoch 13]: 100%|██████████| 7/7 [00:00<00:00,  9.98it/s, g_loss=0.0517, d_loss=0.046] \n",
      "[Epoch 14]: 100%|██████████| 7/7 [00:00<00:00, 10.04it/s, g_loss=0.0568, d_loss=0.0358]\n",
      "[Epoch 15]: 100%|██████████| 7/7 [00:00<00:00, 10.11it/s, g_loss=0.066, d_loss=0.0277] \n",
      "[Epoch 16]: 100%|██████████| 7/7 [00:00<00:00, 10.18it/s, g_loss=0.0952, d_loss=0.018] \n",
      "[Epoch 17]: 100%|██████████| 7/7 [00:00<00:00,  8.07it/s, g_loss=0.139, d_loss=0.00891]\n",
      "[Epoch 18]: 100%|██████████| 7/7 [00:00<00:00,  7.61it/s, g_loss=0.166, d_loss=0.0384] \n",
      "[Epoch 19]: 100%|██████████| 7/7 [00:00<00:00, 10.45it/s, g_loss=0.16, d_loss=0.00559] \n",
      "[Epoch 20]: 100%|██████████| 7/7 [00:00<00:00, 10.51it/s, g_loss=0.198, d_loss=0.0029] \n",
      "[Epoch 21]: 100%|██████████| 7/7 [00:00<00:00, 10.56it/s, g_loss=0.225, d_loss=0.00182]\n",
      "[Epoch 22]: 100%|██████████| 7/7 [00:00<00:00, 10.56it/s, g_loss=0.247, d_loss=0.0013] \n",
      "[Epoch 23]: 100%|██████████| 7/7 [00:00<00:00, 10.56it/s, g_loss=0.266, d_loss=0.00101]\n",
      "[Epoch 24]: 100%|██████████| 7/7 [00:00<00:00, 10.42it/s, g_loss=0.28, d_loss=0.000854] \n",
      "[Epoch 25]: 100%|██████████| 7/7 [00:00<00:00, 10.21it/s, g_loss=0.292, d_loss=0.000713]\n",
      "[Epoch 26]: 100%|██████████| 7/7 [00:00<00:00, 10.30it/s, g_loss=0.302, d_loss=0.000609]\n",
      "[Epoch 27]: 100%|██████████| 7/7 [00:00<00:00, 10.43it/s, g_loss=0.311, d_loss=0.000534]\n",
      "[Epoch 28]: 100%|██████████| 7/7 [00:00<00:00, 10.54it/s, g_loss=0.317, d_loss=0.000467]\n",
      "[Epoch 29]: 100%|██████████| 7/7 [00:00<00:00, 10.39it/s, g_loss=0.323, d_loss=0.000404]\n",
      "[Epoch 30]: 100%|██████████| 7/7 [00:00<00:00, 10.44it/s, g_loss=0.329, d_loss=0.000376]\n",
      "[Epoch 31]: 100%|██████████| 7/7 [00:00<00:00, 10.27it/s, g_loss=0.334, d_loss=0.000341]\n",
      "[Epoch 32]: 100%|██████████| 7/7 [00:00<00:00, 10.41it/s, g_loss=0.339, d_loss=0.000305]\n",
      "[Epoch 33]: 100%|██████████| 7/7 [00:00<00:00, 10.35it/s, g_loss=0.345, d_loss=0.000277]\n",
      "[Epoch 34]: 100%|██████████| 7/7 [00:00<00:00, 10.32it/s, g_loss=0.35, d_loss=0.000256] \n",
      "[Epoch 35]: 100%|██████████| 7/7 [00:00<00:00, 10.08it/s, g_loss=0.354, d_loss=0.000237]\n",
      "[Epoch 36]: 100%|██████████| 7/7 [00:00<00:00, 10.10it/s, g_loss=0.359, d_loss=0.000218]\n",
      "[Epoch 37]: 100%|██████████| 7/7 [00:00<00:00, 10.08it/s, g_loss=0.363, d_loss=0.000204]\n",
      "[Epoch 38]: 100%|██████████| 7/7 [00:00<00:00, 10.56it/s, g_loss=0.367, d_loss=0.000188]\n",
      "[Epoch 39]: 100%|██████████| 7/7 [00:00<00:00, 10.33it/s, g_loss=0.371, d_loss=0.000179]\n",
      "[Epoch 40]: 100%|██████████| 7/7 [00:00<00:00, 10.33it/s, g_loss=0.375, d_loss=0.000167]\n",
      "[Epoch 41]: 100%|██████████| 7/7 [00:00<00:00, 10.01it/s, g_loss=0.378, d_loss=0.000158]\n",
      "[Epoch 42]: 100%|██████████| 7/7 [00:00<00:00, 10.33it/s, g_loss=0.382, d_loss=0.000148]\n",
      "[Epoch 43]: 100%|██████████| 7/7 [00:00<00:00, 10.09it/s, g_loss=0.385, d_loss=0.00014] \n",
      "[Epoch 44]: 100%|██████████| 7/7 [00:00<00:00, 10.45it/s, g_loss=0.388, d_loss=0.000132]\n",
      "[Epoch 45]: 100%|██████████| 7/7 [00:00<00:00, 10.63it/s, g_loss=0.392, d_loss=0.000122]\n",
      "[Epoch 46]: 100%|██████████| 7/7 [00:00<00:00, 10.48it/s, g_loss=0.396, d_loss=0.000116]\n",
      "[Epoch 47]: 100%|██████████| 7/7 [00:00<00:00, 10.48it/s, g_loss=0.398, d_loss=0.000112]\n",
      "[Epoch 48]: 100%|██████████| 7/7 [00:00<00:00,  9.88it/s, g_loss=0.402, d_loss=0.000105]\n",
      "[Epoch 49]: 100%|██████████| 7/7 [00:00<00:00,  9.61it/s, g_loss=0.403, d_loss=0.000103]\n",
      "[Epoch 50]: 100%|██████████| 7/7 [00:00<00:00,  9.82it/s, g_loss=0.407, d_loss=9.46e-5] \n",
      "[Epoch 51]: 100%|██████████| 7/7 [00:00<00:00,  7.70it/s, g_loss=0.409, d_loss=9.34e-5] \n",
      "[Epoch 52]: 100%|██████████| 7/7 [00:00<00:00,  7.55it/s, g_loss=0.412, d_loss=8.84e-5]\n",
      "[Epoch 53]: 100%|██████████| 7/7 [00:00<00:00,  8.41it/s, g_loss=0.414, d_loss=8.47e-5] \n",
      "[Epoch 54]: 100%|██████████| 7/7 [00:00<00:00,  8.48it/s, g_loss=0.417, d_loss=8.11e-5] \n",
      "[Epoch 55]: 100%|██████████| 7/7 [00:00<00:00,  8.75it/s, g_loss=0.419, d_loss=7.78e-5] \n",
      "[Epoch 56]: 100%|██████████| 7/7 [00:00<00:00,  8.47it/s, g_loss=0.423, d_loss=7.3e-5]  \n",
      "[Epoch 57]: 100%|██████████| 7/7 [00:00<00:00,  8.05it/s, g_loss=0.423, d_loss=7.39e-5] \n",
      "[Epoch 58]: 100%|██████████| 7/7 [00:00<00:00,  8.24it/s, g_loss=0.426, d_loss=6.95e-5] \n",
      "[Epoch 59]: 100%|██████████| 7/7 [00:00<00:00,  7.78it/s, g_loss=0.428, d_loss=6.8e-5]  \n",
      "[Epoch 60]: 100%|██████████| 7/7 [00:00<00:00,  7.33it/s, g_loss=0.429, d_loss=6.65e-5] \n",
      "[Epoch 61]: 100%|██████████| 7/7 [00:00<00:00,  8.13it/s, g_loss=0.433, d_loss=6.23e-5] \n",
      "[Epoch 62]: 100%|██████████| 7/7 [00:00<00:00,  9.44it/s, g_loss=0.434, d_loss=6.2e-5]  \n",
      "[Epoch 63]: 100%|██████████| 7/7 [00:00<00:00,  7.93it/s, g_loss=0.437, d_loss=5.75e-5] \n",
      "[Epoch 64]: 100%|██████████| 7/7 [00:00<00:00,  7.90it/s, g_loss=0.438, d_loss=5.75e-5] \n",
      "[Epoch 65]: 100%|██████████| 7/7 [00:00<00:00,  8.66it/s, g_loss=0.441, d_loss=5.45e-5] \n",
      "[Epoch 66]: 100%|██████████| 7/7 [00:00<00:00,  8.63it/s, g_loss=0.441, d_loss=5.45e-5] \n",
      "[Epoch 67]: 100%|██████████| 7/7 [00:00<00:00,  8.57it/s, g_loss=0.445, d_loss=5.13e-5] \n",
      "[Epoch 68]: 100%|██████████| 7/7 [00:00<00:00,  8.34it/s, g_loss=0.445, d_loss=5.12e-5] \n",
      "[Epoch 69]: 100%|██████████| 7/7 [00:00<00:00,  8.52it/s, g_loss=0.447, d_loss=4.98e-5] \n",
      "[Epoch 70]: 100%|██████████| 7/7 [00:00<00:00,  8.41it/s, g_loss=0.45, d_loss=4.77e-5] \n",
      "[Epoch 71]: 100%|██████████| 7/7 [00:00<00:00,  8.56it/s, g_loss=0.451, d_loss=4.72e-5]\n",
      "[Epoch 72]: 100%|██████████| 7/7 [00:00<00:00,  8.84it/s, g_loss=0.454, d_loss=4.5e-5]  \n",
      "[Epoch 73]: 100%|██████████| 7/7 [00:00<00:00,  8.75it/s, g_loss=0.455, d_loss=4.46e-5] \n",
      "[Epoch 74]: 100%|██████████| 7/7 [00:00<00:00,  8.42it/s, g_loss=0.459, d_loss=4.14e-5] \n",
      "[Epoch 75]: 100%|██████████| 7/7 [00:00<00:00,  8.58it/s, g_loss=0.46, d_loss=4.12e-5]  \n",
      "[Epoch 76]: 100%|██████████| 7/7 [00:00<00:00,  8.50it/s, g_loss=0.463, d_loss=3.91e-5]\n",
      "[Epoch 77]: 100%|██████████| 7/7 [00:00<00:00,  8.53it/s, g_loss=0.465, d_loss=3.85e-5] \n",
      "[Epoch 78]: 100%|██████████| 7/7 [00:00<00:00, 10.55it/s, g_loss=0.468, d_loss=3.65e-5] \n",
      "[Epoch 79]: 100%|██████████| 7/7 [00:00<00:00, 10.57it/s, g_loss=0.469, d_loss=3.64e-5]\n",
      "[Epoch 80]: 100%|██████████| 7/7 [00:00<00:00, 10.62it/s, g_loss=0.473, d_loss=3.41e-5]\n",
      "[Epoch 81]: 100%|██████████| 7/7 [00:00<00:00, 10.43it/s, g_loss=0.476, d_loss=3.28e-5]\n",
      "[Epoch 82]: 100%|██████████| 7/7 [00:00<00:00, 10.07it/s, g_loss=0.476, d_loss=3.26e-5]\n",
      "[Epoch 83]: 100%|██████████| 7/7 [00:00<00:00, 10.43it/s, g_loss=0.478, d_loss=3.15e-5]\n",
      "[Epoch 84]: 100%|██████████| 7/7 [00:00<00:00,  9.16it/s, g_loss=0.481, d_loss=3.03e-5]\n",
      "[Epoch 85]: 100%|██████████| 7/7 [00:00<00:00,  8.43it/s, g_loss=0.484, d_loss=2.88e-5]\n",
      "[Epoch 86]: 100%|██████████| 7/7 [00:00<00:00,  8.43it/s, g_loss=0.487, d_loss=2.78e-5]\n",
      "[Epoch 87]: 100%|██████████| 7/7 [00:00<00:00,  8.47it/s, g_loss=0.49, d_loss=2.6e-5]  \n",
      "[Epoch 88]: 100%|██████████| 7/7 [00:00<00:00,  8.25it/s, g_loss=0.493, d_loss=2.5e-5] \n",
      "[Epoch 89]: 100%|██████████| 7/7 [00:00<00:00,  8.65it/s, g_loss=0.496, d_loss=2.36e-5]\n",
      "[Epoch 90]: 100%|██████████| 7/7 [00:00<00:00,  8.66it/s, g_loss=0.499, d_loss=2.29e-5]\n",
      "[Epoch 91]: 100%|██████████| 7/7 [00:00<00:00, 10.50it/s, g_loss=0.501, d_loss=2.15e-5]\n",
      "[Epoch 92]: 100%|██████████| 7/7 [00:00<00:00, 10.64it/s, g_loss=0.503, d_loss=2.15e-5]\n",
      "[Epoch 93]: 100%|██████████| 7/7 [00:00<00:00, 10.63it/s, g_loss=0.505, d_loss=2.05e-5]\n",
      "[Epoch 94]: 100%|██████████| 7/7 [00:00<00:00,  9.47it/s, g_loss=0.507, d_loss=2.02e-5]\n",
      "[Epoch 95]: 100%|██████████| 7/7 [00:00<00:00,  8.47it/s, g_loss=0.51, d_loss=1.87e-5] \n",
      "[Epoch 96]: 100%|██████████| 7/7 [00:00<00:00,  8.58it/s, g_loss=0.511, d_loss=1.92e-5]\n",
      "[Epoch 97]: 100%|██████████| 7/7 [00:00<00:00,  8.46it/s, g_loss=0.514, d_loss=1.71e-5]\n",
      "[Epoch 98]: 100%|██████████| 7/7 [00:00<00:00, 10.56it/s, g_loss=0.515, d_loss=1.84e-5]\n",
      "[Epoch 99]: 100%|██████████| 7/7 [00:00<00:00, 10.53it/s, g_loss=0.516, d_loss=1.58e-5]\n"
     ]
    }
   ],
   "source": [
    "# generate a batch of noisy input\n",
    "test_z = tf.random.normal(shape=(256, 256, 1))\n",
    "\n",
    "# start loop\n",
    "for epoch in range(100): \n",
    "    with tqdm(training_ds) as pbar:\n",
    "        pbar.set_description(f\"[Epoch {epoch}]\")\n",
    "        for step, X in enumerate(pbar):\n",
    "            # train on the current batch\n",
    "            d_loss, g_loss, fake = train_on_batch(X)\n",
    "\n",
    "            # display the losses\n",
    "            pbar.set_postfix({\"g_loss\": g_loss.numpy(), \"d_loss\": d_loss.numpy()})\n",
    "    \n",
    "        # generate fake images\n",
    "        #fake_img = model_G(test_z)\n",
    "\n",
    "    # save output\n",
    "    # if not os.path.exists(out_dir):\n",
    "    #     os.makedirs(out_dir)\n",
    "    # file_path = out_dir+f\"/epoch_{epoch:04}.png\"\n",
    "    # if epoch % 100 == 0:\n",
    "    #     save_img(fake_img.numpy()[:64], file_path, 8)\n",
    "    \n",
    "    # display gallery of fake faces\n",
    "    # if epoch % 1 == 0:\n",
    "    #     with Image.open(file_path) as img:\n",
    "    #         plt.imshow(np.asarray(img))\n",
    "    #         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d346848a-1a91-464d-a5e7-32bbff50032c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 3)\n",
      "(256, 256)\n"
     ]
    }
   ],
   "source": [
    "for img in training_ds.take(1):\n",
    "    print(img.shape)                     \n",
    "    D = img[...,0]\n",
    "    print(D.shape)\n",
    "    \n",
    "D = tf.reshape(D, [1, 256, 256, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e884999e-f285-481a-a1a8-9901dca2428f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img = model_G(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4715b5d5-1799-4871-b65d-1a75d38721a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc818169910>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = tf.reshape(img,[256,256,1])\n",
    "img = tf.cast(img*255, tf.uint8)\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a575754-9aa0-44b3-afe2-b52676565789",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
